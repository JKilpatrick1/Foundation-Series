{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ AG2 Foundations: Tools\n",
    "\n",
    "Welcome! This notebook walks you through the foundations of using **tools** in the AG2 (AutoGen) framework.\n",
    "\n",
    "Tools are a core part of how agents take meaningful actions ‚Äî from doing math to making API calls, searching the web, or extracting knowledge from text. This notebook is structured to guide you step-by-step, with each section building on the last.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö What You‚Äôll Learn\n",
    "\n",
    "- How to define and register your own tools  \n",
    "- How to inject secrets into tools safely  \n",
    "- How to integrate tools from other frameworks\n",
    "- How to use AG2's built-in reference tools  \n",
    "- How to orchestrate multiple tools in a full research workflow\n",
    "\n",
    "Let‚Äôs dive in and start building intelligent, tool-using agents!\n",
    "\n",
    "**Note:** For this demo you will need a few extra dependcies:\n",
    "\n",
    "```bash\n",
    "pip install ag2[openai,interop-langchain,google-search]\n",
    "pip install langchain_community\n",
    "pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è LLM Configuration\n",
    "\n",
    "Make sure to use a model that supports structured tool calling and has strong reasoning capabilities, so the agent can correctly decide which tools to call and when.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import LLMConfig\n",
    "\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Tool Usage Between Agents: Simple Math Example\n",
    "\n",
    "In this example, we define a minimal tool (`add_numbers`) and demonstrate how two agents can collaborate to use it.\n",
    "\n",
    "- **The tool:** A basic function that adds two integers.\n",
    "- **The addition agent** acts as the *caller* ‚Äî it has reasoning capabilities and decides when to use the tool based on the user's question.\n",
    "- **The executor agent** is the *executor* ‚Äî it doesn't talk to the user but runs the actual function when instructed.\n",
    "- We use `register_function` to make the tool available to the agents.\n",
    "- Finally, the user asks a question like \"What is 2 + 2?\", and the `addition_agent` will use the function to help answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, register_function\n",
    "\n",
    "# 1. Define a function\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "# 2. Create an agent that will decide when to use the tool (the \"caller\")\n",
    "addition_agent = ConversableAgent(\n",
    "    name=\"addition_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful math assistant that can only do addition. reply in this format 'x + y = z'\", \n",
    ")\n",
    "\n",
    "# 3. Create another agent that will execute the tool (the \"executor\")\n",
    "executor_agent = ConversableAgent(\n",
    "    name=\"executor\",\n",
    "    human_input_mode=\"NEVER\",  \n",
    "    is_termination_msg=lambda x: \"=\" in (x.get(\"content\", \"\") or \"\").upper() # terminate chat when input has '=' \n",
    ")\n",
    "\n",
    "# 4. Register the tool function with both agents\n",
    "register_function(\n",
    "    add_numbers,\n",
    "    caller=addition_agent,    \n",
    "    executor=executor_agent,   \n",
    "    description=\"Add two numbers together\",  # description helps the LLM know what the tool does and when to use it\n",
    ")\n",
    "\n",
    "# 5. Ask a question that requires the tool\n",
    "result = executor_agent.initiate_chat(\n",
    "    recipient=addition_agent,\n",
    "    message=\"What is 2 + 2?\",\n",
    "    # max_turns=2  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì° Tool with Secrets\n",
    "\n",
    "Secrets such as password, tokens, or personal information needs to be protected from capture. AG2 provides dependency injection as a way to secure this sensitive information while still allowing agents to perform their tasks effectively, even when working with large language models (LLMs).\n",
    "\n",
    "**Benefits of dependency injection:**\n",
    "\n",
    "- **Enhanced Security:** Your sensitive data is never directly exposed to the LLM or telemetry.  \n",
    "- **Simplified Development:** Secure data can be seamlessly accessed by functions without requiring complex configurations.  \n",
    "- **Unmatched Flexibility:** Supports safe integration of diverse workflows, allowing you to scale and adapt with ease.\n",
    "\n",
    "In this walk-through we‚Äôll show how you could support 3rd party system credentials using specific agents and their respective tools and dependency injection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from pydantic import BaseModel\n",
    "from autogen import ConversableAgent, register_function\n",
    "from autogen.tools.dependency_injection import BaseContext, Depends\n",
    "\n",
    "# Mock weather API function (pretending to hit a third-party API)\n",
    "def weather_api_call(username: str, password: str, location: str) -> str:\n",
    "    print(f\"Accessing third party Weather System using username {username}\")\n",
    "    return \"It's sunny and 40 degrees Celsius in Sydney, Australia.\"\n",
    "\n",
    "# Define a context class to store secret credentials\n",
    "class ThirdPartyCredentials(BaseContext, BaseModel):\n",
    "    username: str\n",
    "    password: str\n",
    "\n",
    "weather_account = ThirdPartyCredentials(username=\"ag2weather\", password=\"wbkvEehV1A\")\n",
    "\n",
    "# function that receives location input and gets credentials injected\n",
    "def get_weather(\n",
    "    location: str,\n",
    "    credentials: Annotated[ThirdPartyCredentials, Depends(weather_account)],\n",
    ") -> str:\n",
    "    # Access the Weather API using the credentials\n",
    "    return weather_api_call(username=credentials.username, password=credentials.password, location=location)\n",
    "\n",
    "weather_agent = ConversableAgent(\n",
    "    name=\"weather_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a weather assistant.\"\n",
    ")\n",
    "\n",
    "executor_agent = ConversableAgent(name=\"executor\", human_input_mode=\"NEVER\")\n",
    "\n",
    "register_function(\n",
    "    get_weather,\n",
    "    caller=weather_agent,\n",
    "    executor=executor_agent,\n",
    "    description=\"Gets weather for given location\"\n",
    ")\n",
    "\n",
    "query = \"Get weather for Sydney, Australia\"\n",
    "result = executor_agent.initiate_chat(recipient=weather_agent, message=query, max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Tool Interoperability \n",
    "\n",
    "AG2 supports tool interoperability with popular agent frameworks like **LangChain**, **CrewAI**, and **Pydantic**. Using AG2‚Äôs `Interoperability` module, you can convert tools from these ecosystems into AG2-compatible functions with just one line of code.\n",
    "\n",
    "In this demo, we:\n",
    "\n",
    "- Use a LangChain-based ArXiv tool\n",
    "- Convert it into an AG2-compatible tool \n",
    "- Register and use it inside a `ConversableAgent` just like any native tool\n",
    "\n",
    "This makes it easy to **reuse existing tooling** and integrate with external agent stacks without rewriting functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "from autogen.interop import Interoperability\n",
    "\n",
    "# Initialize LangChain Wikipedia tool\n",
    "api_wrapper = ArxivAPIWrapper()\n",
    "langchain_tool = ArxivQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "\n",
    "# Convert to AG2 tool\n",
    "interop = Interoperability()\n",
    "ag2_arXiv_tool = interop.convert_tool(tool=langchain_tool, type=\"langchain\")\n",
    "\n",
    "\n",
    "arxiv_agent = ConversableAgent(\n",
    "    name=\"arxiv_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are helpful ai assistant\"\n",
    ")\n",
    "\n",
    "executor_agent = ConversableAgent(name=\"executor\", human_input_mode=\"NEVER\")\n",
    "\n",
    "# Register the converted LangChain tool just like any other function\n",
    "register_function(\n",
    "    ag2_arXiv_tool,\n",
    "    caller=arxiv_agent,\n",
    "    executor=executor_agent,\n",
    "    description=\"Search and retrieve academic papers from ArXiv.\"\n",
    ")\n",
    "\n",
    "\n",
    "query = \"Tell me about llm prompting\"\n",
    "result = executor_agent.initiate_chat(\n",
    "    recipient=arxiv_agent, \n",
    "    message=query, \n",
    "    max_turns=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåê Reference Tools in AG2\n",
    "\n",
    "In this section, we'll demonstrate how to enhance an AG2 agent's capabilities with reference tools by integrating the **Google Search Tool**. This tool enables the agent to perform real-time web searches, providing up-to-date information beyond its training data.\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- **Google Search API Key:** Obtain from the [Google Cloud Console](https://console.cloud.google.com/).\n",
    "- **Search Engine ID:** Set up a custom search engine via the [Google Programmable Search Engine](https://programmablesearchengine.google.com/).\n",
    "\n",
    "**Note:** You will need to install `ag2[google]` and set environment variables for `GOOGLE_SEARCH_API_KEY` and `GOOGLE_SEARCH_ENGINE_ID`.\n",
    "\n",
    "---\n",
    "\n",
    "- Load the reference `GoogleSearchTool` from AG2.\n",
    "- Configures it with API credentials.\n",
    "- Registers it as a tool callable by a `ConversableAgent`.\n",
    "- Executes a web search using the agent.\n",
    "\n",
    "This shows how AG2's **reference tools** let you extend agent capabilities with minimal setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent, register_function\n",
    "from autogen import AssistantAgent, LLMConfig\n",
    "from autogen.tools.experimental import GoogleSearchTool\n",
    "\n",
    "# Load Google Search API credentials from environment variables\n",
    "search_api_key = os.getenv(\"GOOGLE_SEARCH_API_KEY\")\n",
    "search_engine_id = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")\n",
    "\n",
    "# Initialize the Google Search tool with your API key and search engine ID\n",
    "gs_tool = GoogleSearchTool(\n",
    "    search_api_key=search_api_key,\n",
    "    search_engine_id=search_engine_id,\n",
    ")\n",
    "\n",
    "gs_agent = ConversableAgent(\n",
    "    name=\"gs_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful ai assistant.\"\n",
    ")\n",
    "\n",
    "executor_agent = ConversableAgent(name=\"executor\", human_input_mode=\"NEVER\")\n",
    "\n",
    "register_function(\n",
    "    gs_tool,\n",
    "    caller=gs_agent,\n",
    "    executor=executor_agent,\n",
    "    description=\"Search the web using the Google Search API to retrieve real-time information.\"\n",
    ")\n",
    "\n",
    "query = \"Who is the founder of AG2\"\n",
    "result = executor_agent.initiate_chat(\n",
    "    recipient=gs_agent, \n",
    "    message=query, \n",
    "    max_turns=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† ML Research Assistant: Multi-Tool Orchestration\n",
    "\n",
    "In this final demo, we combine everything you've learned into a single, powerful agent.\n",
    "\n",
    "The `ml_research_agent` has access to three tools:\n",
    "- üß™ **Custom Function** ‚Äì Method extraction tool for identifying ML techniques like GPT, Transformer, BERT, etc.\n",
    "- üìÑ **Arxiv Search Tool** ‚Äì for academic papers and abstracts\n",
    "- üåê **Google Search Tool** ‚Äì for real-time web results\n",
    "\n",
    "Unlike earlier examples where the agent had just one tool, this agent now has access to multiple tools and must reason about **when and how to use each one**.  \n",
    "This is where **clear system messages and strong tool descriptions** become essential ‚Äî guiding the agent to make correct decisions in multi-step workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"diagram.png\" alt=\"Alt text\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def extract_methods(text: str) -> List[str]:\n",
    "    methods = [\"Transformer\", \"LLM\", \"CNN\", \"RNN\", \"BERT\", \"GPT\", \"LSTM\", \"Reinforcement Learning\", \"Diffusion\", \"Autoencoder\"]\n",
    "    return [m for m in methods if m.lower() in text.lower()]\n",
    "\n",
    "\n",
    "ml_research_agent = ConversableAgent(\n",
    "    name=\"research_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message= \n",
    "    '''\n",
    "    You are a machine learning research assistant with access to three tools: web search, Arxiv paper search, and method extraction.\n",
    "\n",
    "    Your task is to:\n",
    "    1. Use the Arxiv and Google Search tools to retrieve context on query.\n",
    "    2. After you have context use the method extraction tool.\n",
    "    3. After you retrieved context and extracted terms then summarize and list extracted terms. Conclude the research session by responding with 'TERMINATE'.\n",
    "\n",
    "    Note: Use each tool no more than once during the entire research process.\n",
    "    '''\n",
    ")\n",
    "\n",
    "executor_agent = ConversableAgent(\n",
    "    name=\"executor\",\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    extract_methods,\n",
    "    caller=ml_research_agent,\n",
    "    executor=executor_agent,\n",
    "    description=\"After retireving context this tool identifies and returns relevant terms from text (e.g., Transformer, GPT, CNN).\"\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    ag2_arXiv_tool,\n",
    "    caller=ml_research_agent,\n",
    "    executor=executor_agent,\n",
    "    description=\"Search and retrieve scientific papers and abstracts from arXiv.\"\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    gs_tool,\n",
    "    caller=ml_research_agent,\n",
    "    executor=executor_agent,\n",
    "    description=\"Search the web using the Google Search API for up-to-date research or factual information.\"\n",
    ")\n",
    "\n",
    "query = \"How does chatgpt work\"\n",
    "result = executor_agent.initiate_chat(\n",
    "    recipient=ml_research_agent, \n",
    "    message=query, \n",
    "    max_turns=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
